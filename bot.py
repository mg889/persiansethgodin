import os
import re
import time
import html
import feedparser
from bs4 import BeautifulSoup
from telegram import Bot
from googletrans import Translator

# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² Secrets ---
TOKEN = os.getenv("BOT_TOKEN")        # ØªÙˆÚ©Ù† Ø§Ø² BotFather
CHANNEL_ID = os.getenv("CHANNEL_ID")  # Ù…Ø«Ù„Ø§ "@persiansethgodin"
LAST_FILE = "last_post.txt"

bot = Bot(token=TOKEN)
translator = Translator()

# --- ØªÙ…ÛŒØ²Ú©Ø§Ø±ÛŒ Ù…ØªÙ†: Ø­Ø°Ù HTML/URL/Ø§Ø¹Ø¯Ø§Ø¯/ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø¶Ø§ÙÛŒ ---
def clean_text(raw_html: str) -> str:
    if not raw_html:
        return ""
    # ØªØ¨Ø¯ÛŒÙ„ entity Ù‡Ø§ Ù…Ø«Ù„ &amp; Ùˆ &#8217; Ø¨Ù‡ Ú©Ø§Ø±Ø§Ú©ØªØ± Ù…Ø¹Ù…ÙˆÙ„ÛŒ
    text = html.unescape(raw_html)

    # Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ÛŒ HTML
    text = BeautifulSoup(text, "html.parser").get_text(separator=" ")

    # Ø­Ø°Ù Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡â€ŒÛŒ entityÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (Ø§Ø­ØªÛŒØ§Ø·ÛŒ)
    text = re.sub(r'&#\d+;?', ' ', text)

    # Ø­Ø°Ù Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§
    text = re.sub(r'http\S+', ' ', text)

    # Ø­Ø°Ù Ú©Ù„Ù…Ø§Øª Ø§Ø¶Ø§ÙÛŒ HTML Ù…Ø§Ù†Ù†Ø¯ amp; / nbsp;
    text = re.sub(r'\b(?:amp|nbsp);?\b', ' ', text, flags=re.I)

    # Ø­Ø°Ù ØªÙ…Ø§Ù… Ø§Ø¹Ø¯Ø§Ø¯ (Ø§Ú¯Ø± Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒ Ù‡Ù…Ù‡ Ø§Ø¹Ø¯Ø§Ø¯ Ø­Ø°Ù Ø´Ù†ØŒ Ø§ÛŒÙ† Ø®Ø· Ø±Ùˆ Ø¨Ø±Ø¯Ø§Ø±)
    text = re.sub(r'\d+', ' ', text)

    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§
    text = re.sub(r'\s+', ' ', text).strip()
    return text

# --- ØªØ±Ø¬Ù…Ù‡ Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ (Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨ÛŒØ´ØªØ±) ---
def translate_fa(en_text: str) -> str:
    if not en_text:
        return ""
    for i in range(3):  # ØªØ§ 3 Ø¨Ø§Ø± ØªÙ„Ø§Ø´
        try:
            fa = translator.translate(en_text, src="en", dest="fa").text
            fa = re.sub(r'\s+', ' ', fa).strip()
            if fa:
                return fa
        except Exception as e:
            print(f"[warn] translate attempt {i+1} failed: {e}")
            time.sleep(2 + i)  # Ù…Ú©Ø« Ú©ÙˆØªØ§Ù‡ Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù†
    return ""  # Ø§Ú¯Ø± ØªØ±Ø¬Ù…Ù‡ Ù†Ø´Ø¯ØŒ Ø®Ø§Ù„ÛŒ Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯ÙˆÙ†ÛŒÙ…

def get_last_post_id() -> str | None:
    try:
        with open(LAST_FILE, "r", encoding="utf-8") as f:
            return f.read().strip()
    except FileNotFoundError:
        return None

def save_last_post_id(pid: str):
    with open(LAST_FILE, "w", encoding="utf-8") as f:
        f.write(pid or "")

# ØªÙ‚Ø³ÛŒÙ… Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯ (Ù…Ø­Ø¯ÙˆØ¯ÛŒØª ØªÙ„Ú¯Ø±Ø§Ù… ~4096 Ú©Ø§Ø±Ø§Ú©ØªØ±)
def send_long_message(text: str):
    max_len = 4000
    for i in range(0, len(text), max_len):
        bot.send_message(chat_id=CHANNEL_ID, text=text[i:i + max_len])

def main():
    feed_url = "https://seths.blog/feed"
    feed = feedparser.parse(feed_url)
    if not feed.entries:
        print("[info] no entries in feed.")
        return

    entry = feed.entries[0]
    title = entry.get("title", "(Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†)")
    link = entry.get("link", "")

    # Ø¨Ø±Ø®ÛŒ ÙˆÙ‚Øªâ€ŒÙ‡Ø§ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± summary Ø§Ø³ØªØŒ Ú¯Ø§Ù‡ÛŒ Ø¯Ø± content
    raw = entry.get("summary") or (entry.get("content", [{}])[0].get("value") if entry.get("content") else "")
    en_clean = clean_text(raw)

    # ÙÙ‚Ø· Ø§Ú¯Ø± Ù¾Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø³Øª Ø§Ø±Ø³Ø§Ù„ Ú©Ù†
    last = get_last_post_id()
    if last == link:
        print("[info] no new post.")
        return

    # ØªØ±Ø¬Ù…Ù‡
    fa_text = translate_fa(en_clean)

    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…
    # Ø¨Ø±Ø§ÛŒ Ø²ÛŒØ¨Ø§ÛŒÛŒØŒ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø±Ø§ Ø®ÛŒÙ„ÛŒ Ø¨Ù„Ù†Ø¯ Ù†Ú©Ù†ÛŒÙ…
    en_preview = en_clean if len(en_clean) <= 1000 else en_clean[:1000].rstrip() + "..."

    parts = [f"ğŸ“Œ {title}", "", f"ğŸ‡¬ğŸ‡§ {en_preview}"]
    if fa_text:
        parts += ["", f"ğŸ‡®ğŸ‡· {fa_text}"]
    parts += ["", f"ğŸ”— Ù…Ù†Ø¨Ø¹: {link}"]

    message = "\n".join(parts)
    send_long_message(message)

    save_last_post_id(link)
    print("[ok] message sent and last_post saved.")

if __name__ == "__main__":
    main()    if not text:
        return ""

    # ØªÙ‚Ø³ÛŒÙ… Ù…ØªÙ† Ø¨Ù‡ Ø¬Ù…Ù„Ø§Øª (ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹)
    sentences = re.split(r'(?<=[.!?])\s+', text)

    chunks = []
    cur = ""
    for s in sentences:
        # Ø¨Ø± Ø§Ø³Ø§Ø³ Ø·ÙˆÙ„ Ú©Ø§Ø±Ø§Ú©ØªØ± ØªÙ‚Ø³ÛŒÙ… Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… (ØªÙ‚Ø±ÛŒØ¨ÛŒØ› ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ù‡Ù… Ø¯Ø± Ù…Ø¯Ù„ Ú©Ù†ØªØ±Ù„ Ù…ÛŒØ´Ù†)
        if not cur:
            cur = s
        elif len(cur) + len(s) < 1000:  # Ø­Ø¯ÙˆØ¯ÛŒØ› Ø§Ú¯Ø± Ù…ØªÙ† Ø®ÛŒÙ„ÛŒ Ø¨Ù„Ù†Ø¯Ù‡ Ø§ÛŒÙ† Ø¹Ø¯Ø¯ Ø±Ùˆ Ú©Ù…/Ø²ÛŒØ§Ø¯ Ú©Ù†
            cur += " " + s
        else:
            chunks.append(cur)
            cur = s
    if cur:
        chunks.append(cur)

    translations = []
    for chunk in chunks:
        # encode
        inputs = tokenizer(chunk, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
        translated_tokens = model.generate(**inputs, max_length=512)
        out = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]
        translations.append(out)

    return " ".join(translations).strip()

# ---------- Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø·ÙˆÙ„Ø§Ù†ÛŒ (ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ Ù‚Ø·Ø¹Ø§Øª Ø­Ø¯Ø§Ú©Ø«Ø± ~4000 Ú©Ø§Ø±Ø§Ú©ØªØ±) ----------
def send_long_message(bot, chat_id, text):
    max_len = 4000
    parts = [text[i:i+max_len] for i in range(0, len(text), max_len)]
    for p in parts:
        bot.send_message(chat_id=chat_id, text=p)

# ---------- Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ù„ÛŒÙ†Ú© ----------
def get_last_post_id():
    if os.path.exists(LAST_FILE):
        with open(LAST_FILE, "r", encoding="utf-8") as f:
            return f.read().strip()
    return None

def save_last_post_id(post_id):
    with open(LAST_FILE, "w", encoding="utf-8") as f:
        f.write(post_id or "")

# ---------- Ù…Ù†Ø·Ù‚ Ø§ØµÙ„ÛŒ ----------
def send_latest_post():
    logger.info("Fetching feed...")
    feed_url = "https://seths.blog/feed"
    feed = feedparser.parse(feed_url)

    if not feed.entries:
        logger.warning("No feed entries found.")
        return

    entry = feed.entries[0]
    title = entry.title if "title" in entry else "(Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†)"
    link = entry.link if "link" in entry else ""
    summary_raw = entry.summary if "summary" in entry else entry.get("content", [{}])[0].get("value", "")

    # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ
    summary_clean = clean_text(summary_raw)

    # Ù…Ù‚Ø§ÛŒØ³Ù‡ Ø¨Ø§ Ø¢Ø®Ø±ÛŒÙ† Ù„ÛŒÙ†Ú© Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡
    last = get_last_post_id()
    if last == link:
        logger.info("No new post (same link). Exiting.")
        return

    # ØªØ±Ø¬Ù…Ù‡ Ù…ØªÙ†
    logger.info("Translating summary to Persian...")
    try:
        summary_fa = translate_text(summary_clean)
    except Exception as e:
        logger.exception("Translation failed, falling back to cleaned English summary.")
        summary_fa = ""  # ÛŒØ§ Ù…ÛŒâ€ŒØ´Ù‡ summary_clean Ø±Ùˆ Ø¨Ø°Ø§Ø±ÛŒÙ…

    # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… (Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ + ÙØ§Ø±Ø³ÛŒ)
    # Ú©ÙˆØªØ§Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø³Ø®Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ø²ÛŒØ¨Ø§ÛŒÛŒ (Ù…Ø«Ù„Ø§Ù‹ 1000 Ú©Ø§Ø±Ø§Ú©ØªØ±)
    en_preview = summary_clean if len(summary_clean) <= 1000 else summary_clean[:1000].rstrip() + "..."

    message = f"ğŸ“Œ {title}\n\nğŸ‡¬ğŸ‡§ {en_preview}\n\nğŸ‡®ğŸ‡· {summary_fa}\n\nğŸ”— Ù…Ù†Ø¨Ø¹: {link}"
    logger.info("Sending message to channel...")
    send_long_message(bot, CHANNEL_ID, message)
    logger.info("Message sent. Saving last_post...")
    save_last_post_id(link)

if __name__ == "__main__":
    send_latest_post()
    # Ø°Ø®ÛŒØ±Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ù„ÛŒÙ†Ú©
    save_last_post_id(link)

if __name__ == "__main__":
    send_latest_post()

if __name__ == "__main__":
    main()
